#!/usr/bin/env python

import argparse
import math
import os
import os.path
import subprocess
import stat
import sys

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Submit commands to a queueing system")
    parser.add_argument('command_file', help="An input file containing a list of commands. Use - for stdin")
    parser.add_argument("-o", default='', help="Quoted string of options to pass to qsub")
    parser.add_argument("-w", default=os.getcwd(), help="Job working directory")
    parser.add_argument("-i", action="store_true", help="Use individual jobs instead of an array job")
    parser.add_argument("-c", default=1, type=int, help="Number of input lines to run in a single job")
    parser.add_argument("-j", default=8, type=int, help="Number of commands to run in parallel per job")
    parser.add_argument("-b", default="sge", choices=['pbs','sge'], help="Queueing system to use")
    parser.add_argument("-n", action="store_true", help="Dry run; nothing is submitted")

    args = parser.parse_args()

    command_file = args.command_file
    qsub_options = args.o
    job_workdir = args.w
    use_individual = args.i
    chunk_size  = args.c
    ncores = args.j
    system = args.b
    dry_run = args.n 

    # read in commands
    job_name = None

    if command_file == '-':
        job_name = 'STDIN'
        task_list =  sys.stdin.readlines()
    else: 
        task_list = open(command_file).readlines()

    job_name = job_name or os.path.basename(command_file)

    # compute the number of jobs needed. This will be the number of elements in
    # the array job
    num_jobs = int(math.ceil(len(task_list) / float(chunk_size)))

    # make options comment block
    options_comment = ''
    if system == 'pbs': 
      options = ['#', '-V', '-d ' + job_workdir, qsub_options] 
      if not use_individual:
          options += ['-t 1-'+str(num_jobs)]
      options_comment = '\n#PBS '.join(options)
    elif system == 'sge':
      options = ['#', '-V', '-wd ' + job_workdir, qsub_options] 
      if not use_individual:
          options += ['-t 1-'+str(num_jobs)]
      options_comment = '\n#$ '.join(options)
      
    shebang = '#!/bin/bash' 

    # emit job scripts
    job_scripts = []
    if not use_individual:
        script_lines = [
                shebang, 
                options_comment,
                'sed -n "$(( (${{SGE_TASK_ID}}-1)*{size}+1)),+$(({size}-1))p" ' 
                  '<< EOF | parallel -j{ncores} '.format(ncores=ncores,size=chunk_size), 
                ''.join(task_list),
                'EOF']

        scriptfile = job_name + ".array"
        script = open(scriptfile, 'w')
        script.write('\n'.join(script_lines))
        script.close()
        job_scripts.append(scriptfile)
    else: 
        for chunk in range(num_jobs):
            scriptfile="{}.{}".format(job_name, chunk)
      
            script_lines = [
                    shebang, 
                    options_comment,
                    "parallel -j{} << EOF".format(ncores), 
                    ''.join(task_list[chunk*chunk_size:chunk*chunk_size+chunk_size]),
                    'EOF']

            script = open(scriptfile, "w") 
            script.write('\n'.join(script_lines))
            script.close()
            job_scripts.append(scriptfile)
   
    # execute the job script(s)
    for script in job_scripts:
        os.chmod(scriptfile, os.stat(scriptfile).st_mode | stat.S_IXUSR)
        if dry_run: continue
        subprocess.call(['qsub', script])
