#!/usr/bin/env python
import argparse
import math
import os
import os.path
import subprocess
import stat
import sys
import fnmatch
import errno

# setup defaults (let environment override)
PPN = os.environ.get("QBATCH_PPN", 12)
NODES = os.environ.get("QBATCH_NODES", 1)
SYSTEM = os.environ.get("QBATCH_SYSTEM", "pbs")
CORES = os.environ.get("QBATCH_CORES", PPN)

def mkdirp(*p):
    """Like mkdir -p"""
    path = os.path.join(*p)

    try:
        os.makedirs(path)
    except OSError as exc:
        if exc.errno == errno.EEXIST:
            pass
        else: raise
    return path

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Submit commands to a queueing system",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("command_file",
                        help="An input file containing a list of commands. Use - for stdin")
    parser.add_argument("opts", nargs='*',
                        help="Options to pass directly to qsub")
    parser.add_argument("-w", default=os.getcwd(),
                        help="Job working directory")
    parser.add_argument("-i", action="store_true",
                        help="Use individual jobs instead of an array job")
    parser.add_argument("-c", default=1, type=int,
                        help="Number of input lines to run in a single job")
    parser.add_argument("-j", default=CORES, type=int,
                        help="Number of commands to run in parallel per job")
    parser.add_argument("-b", default=SYSTEM,
                        choices=['pbs', 'sge'], help="Queueing system to use")
    parser.add_argument("--nodes", default=NODES, type=int,
                        help="Nodes to request per job")
    parser.add_argument("--ppn", default=PPN, type=int,
                        help="Processors per node")
    parser.add_argument("--highmem", action="store_true",
                        help="Submit to high memory nodes")
    parser.add_argument("-n", action="store_true",
                        help="Dry run; nothing is submitted")
    parser.add_argument("--afterok_pattern", action="append",
                        help="Existing jobs matching the given pattern as dependencies.")
    parser.add_argument("--jobname", action="store",
                        help="Override default job name generated from command_file, or set name for STDIN jobs")


    args = parser.parse_args()

    command_file = args.command_file
    qsub_options = args.opts
    job_workdir = args.w
    use_array = not args.i
    chunk_size = args.c
    ncores = args.j
    system = args.b
    dry_run = args.n
    nodes = args.nodes
    ppn = args.ppn
    afterok_pattern = args.afterok_pattern
    highmem = args.highmem
    job_name = args.jobname

    # read in commands
    if command_file == '-':
        job_name = job_name or 'STDIN'
        task_list = sys.stdin.readlines()
    else:
        task_list = open(command_file).readlines()

    job_name = job_name or os.path.basename(command_file)

    # compute the number of jobs needed. This will be the number of elements in
    # the array job
    num_jobs = int(math.ceil(len(task_list) / float(chunk_size)))
    if num_jobs == 0:
        print >>sys.stderr, "No jobs to submit, exiting"
        exit(0)

    # make script header
    shebang = '#!/bin/bash -l'

    if system == 'pbs':
        matching_jobids = []
        if afterok_pattern:
            o = subprocess.check_output('pbs_jobnames')
            for row in o.strip().split("\n"):
                if not row.strip(): # skip empty lines
                    continue
                jobid, name = row.split()
                for pattern in afterok_pattern:
                    if fnmatch.fnmatch(name, pattern):
                        matching_jobids.append(jobid)

        header = '\n'.join([
            "{shebang}",
            "#PBS -l nodes={nodes}{highmem}:ppn={ppn}",
            "#PBS -V",
            "#PBS -d {workdir}",
            "#PBS -N {jobname}",
            "#PBS {options}",
            "#PBS {array}",
            "{dependencies}",
            "ARRAY_IND=PBS_ARRAYID"]).format(
            nodes=nodes,
            highmem=highmem and ':m32g' or '',
            ppn=ppn,
            shebang=shebang,
            workdir=job_workdir,
            jobname=job_name,
            options=' '.join(qsub_options),
            array=use_array and '-t 1-' + str(num_jobs) or '',
            dependencies=matching_jobids and ('#PBS -W depend=' + (use_array and 'afterokarray:' or 'afterok:') + ':'.join(matching_jobids)) or '')
    elif system == 'sge':

        header = '\n'.join([
            "{shebang}",
            "{ppn}",
            "#$ -V",
            "#$ -wd {workdir}",
            "#$ -N {jobname}",
            "#$ {options}",
            "#$ {array}",
            "{dependencies}",
            "ARRAY_IND=SGE_TASK_ID"]).format(
            ppn=(ppn > 1) and '#$ -pe smp ' + str(ppn) or '',
            shebang=shebang,
            workdir=job_workdir,
            jobname=job_name,
            options=' '.join(qsub_options),
            array=use_array and '-t 1-' + str(num_jobs) or '',
            dependencies=afterok_pattern and '#$ -hold_jid ' + afterok_pattern or '')

    # emit job scripts
    job_scripts = []
    mkdirp(".scripts")
    if use_array:
        script_lines = [
            header,
            'sed -n "$(( (${{ARRAY_IND}}-1)*{size}+1)),+$(({size}-1))p" '
            '<< EOF | parallel -j{ncores} '.format(
                ncores=ncores, size=chunk_size),
            ''.join(task_list),
            'EOF']

        scriptfile = ".scripts/" + job_name + ".array"
        script = open(scriptfile, 'w')
        script.write('\n'.join(script_lines))
        script.close()
        job_scripts.append(scriptfile)
    else:
        for chunk in range(num_jobs):
            scriptfile = ".scripts/" + "{}.{}".format(job_name, chunk)
            script_lines = [
                header,
                "parallel -j{} << EOF".format(ncores),
                ''.join(task_list[chunk * chunk_size:chunk *
                                  chunk_size + chunk_size]),
                'EOF']
            script = open(scriptfile, "w")
            script.write('\n'.join(script_lines))
            script.close()
            job_scripts.append(scriptfile)

    # execute the job script(s)
    for script in job_scripts:
        os.chmod(script, os.stat(script).st_mode | stat.S_IXUSR)
        if dry_run:
            continue
        subprocess.call(['qsub', script])
